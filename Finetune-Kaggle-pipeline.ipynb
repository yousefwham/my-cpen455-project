{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/yousefwham/my-cpen455-project.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:05:53.628267Z","iopub.execute_input":"2025-12-02T05:05:53.628488Z","iopub.status.idle":"2025-12-02T05:05:54.348975Z","shell.execute_reply.started":"2025-12-02T05:05:53.628465Z","shell.execute_reply":"2025-12-02T05:05:54.348105Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'my-cpen455-project'...\nremote: Enumerating objects: 83, done.\u001b[K\nremote: Counting objects: 100% (83/83), done.\u001b[K\nremote: Compressing objects: 100% (49/49), done.\u001b[K\nremote: Total 83 (delta 36), reused 76 (delta 33), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (83/83), 148.16 KiB | 2.85 MiB/s, done.\nResolving deltas: 100% (36/36), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/my-cpen455-project","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:05:54.350870Z","iopub.execute_input":"2025-12-02T05:05:54.351159Z","iopub.status.idle":"2025-12-02T05:05:54.357464Z","shell.execute_reply.started":"2025-12-02T05:05:54.351135Z","shell.execute_reply":"2025-12-02T05:05:54.356797Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/my-cpen455-project\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!git clone https://github.com/yousefwham/CPEN455-Project-2025W1-Autograder.git autograder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:05:54.358244Z","iopub.execute_input":"2025-12-02T05:05:54.358479Z","iopub.status.idle":"2025-12-02T05:05:54.863514Z","shell.execute_reply.started":"2025-12-02T05:05:54.358459Z","shell.execute_reply":"2025-12-02T05:05:54.862849Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'autograder'...\nremote: Enumerating objects: 10, done.\u001b[K\nremote: Counting objects: 100% (10/10), done.\u001b[K\nremote: Compressing objects: 100% (8/8), done.\u001b[K\nremote: Total 10 (delta 1), reused 10 (delta 1), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (10/10), 482.92 KiB | 4.39 MiB/s, done.\nResolving deltas: 100% (1/1), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!uv run -m examples.bayes_inverse --method full_finetune","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:07:12.075900Z","iopub.execute_input":"2025-12-02T05:07:12.076491Z","iopub.status.idle":"2025-12-02T05:10:28.460424Z","shell.execute_reply.started":"2025-12-02T05:07:12.076451Z","shell.execute_reply":"2025-12-02T05:10:28.459699Z"}},"outputs":[{"name":"stdout","text":"Using CPython \u001b[36m3.13.2\u001b[39m\nCreating virtual environment at: \u001b[36m.venv\u001b[39m\n\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/67] \u001b[2mInstalling wheels...                                \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m67 packages\u001b[0m \u001b[2min 9.01s\u001b[0m\u001b[0m                              \u001b[0m\n/kaggle/working/my-cpen455-project/.venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/kaggle/working/my-cpen455-project/.venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nUsing device: cuda\nNo cached snapshots found for checkpoint 'HuggingFaceTB/SmolLM2-135M-Instruct'. Attempting to download...\nconfig.json: 100%|█████████████████████████████| 861/861 [00:00<00:00, 7.59MB/s]\ntokenizer.json: 2.10MB [00:00, 38.4MB/s]\ntokenizer_config.json: 3.76kB [00:00, 25.3MB/s]\nFound 1 snapshots in cache\nModel weights file not found: ./cache/huggingface/transformers/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/12fd25f77366fa6b3b4b768ec3050bf629380bac/model.safetensors\nDownloading model weights using huggingface_hub...\nmodel.safetensors: 100%|██████████████████████| 269M/269M [00:01<00:00, 163MB/s]\nModel weights downloaded to: ./cache/huggingface/transformers/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/12fd25f77366fa6b3b4b768ec3050bf629380bac/model.safetensors\nModel successfully downloaded!\nCreating lm_head.weight from embed_tokens.weight\nMissing keys: []\nUnexpected keys: []\nTraining:   9%|██▉                              | 9/100 [00:07<01:16,  1.19it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  8.37it/\u001b[A\nTraining:  19%|██████                          | 19/100 [00:16<01:08,  1.19it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  8.59it/\u001b[A\nTraining:  29%|█████████▎                      | 29/100 [00:24<01:00,  1.17it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  8.50it/\u001b[A\nTraining:  39%|████████████▍                   | 39/100 [00:33<00:52,  1.15it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  8.25it/\u001b[A\nTraining:  49%|███████████████▋                | 49/100 [00:42<00:44,  1.14it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  8.19it/\u001b[A\nTraining:  59%|██████████████████▉             | 59/100 [00:51<00:36,  1.13it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  8.04it/\u001b[A\nTraining:  69%|██████████████████████          | 69/100 [01:00<00:27,  1.11it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  7.90it/\u001b[A\nTraining:  79%|█████████████████████████▎      | 79/100 [01:09<00:19,  1.09it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  7.76it/\u001b[A\nTraining:  89%|████████████████████████████▍   | 89/100 [01:19<00:10,  1.07it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  7.67it/\u001b[A\nTraining:  99%|███████████████████████████████▋| 99/100 [01:28<00:00,  1.08it/s]\nEvaluating on validation set during training:   0%|       | 0/1 [00:00<?, ?it/s]\u001b[A\nEvaluating on validation set during training: 100%|█| 1/1 [00:00<00:00,  7.90it/\u001b[A\nTraining: 100%|███████████████████████████████| 100/100 [01:29<00:00,  1.12it/s]\nsaving probabilities: 100%|███████████████████████| 2/2 [00:00<00:00,  4.63it/s]\nsaving probabilities: 100%|█████████████████████| 63/63 [00:22<00:00,  2.83it/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#uv run -m examples.save_prob_example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:01:41.824478Z","iopub.execute_input":"2025-12-02T05:01:41.824836Z","iopub.status.idle":"2025-12-02T05:01:41.831305Z","shell.execute_reply.started":"2025-12-02T05:01:41.824801Z","shell.execute_reply":"2025-12-02T05:01:41.830244Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_47/1182536616.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    uv run -m examples.save_prob_example\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (1182536616.py, line 1)","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"!pwd\n!ls\n!ls bayes_inverse_probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:22:03.024832Z","iopub.execute_input":"2025-12-02T05:22:03.025098Z","iopub.status.idle":"2025-12-02T05:22:03.365186Z","shell.execute_reply.started":"2025-12-02T05:22:03.025076Z","shell.execute_reply":"2025-12-02T05:22:03.364547Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/my-cpen455-project\nautograder\t     cache     kaggle_submission.csv  pyproject.toml  utils\nbayes_inverse_probs  examples  model\t\t      README.md       uv.lock\ntest_dataset_probs.csv\ttrain_n_val_dataset_probs.csv\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!uv run -m examples.prep_submission_kaggle --input bayes_inverse_probs/test_dataset_probs.csv --output kaggle_submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:19:03.933380Z","iopub.execute_input":"2025-12-02T05:19:03.934155Z","iopub.status.idle":"2025-12-02T05:19:04.511526Z","shell.execute_reply.started":"2025-12-02T05:19:03.934123Z","shell.execute_reply":"2025-12-02T05:19:04.510849Z"}},"outputs":[{"name":"stdout","text":"Input dataset shape: (1000, 3)\nInput columns: ['data_index', 'prob_ham', 'prob_spam']\n\nFirst few rows of input:\n   data_index      prob_ham     prob_spam\n0       22428  2.444039e-11  1.000000e+00\n1        4971  4.596050e-13  1.000000e+00\n2       16377  9.999925e-01  7.463482e-06\n3        5097  4.596050e-13  1.000000e+00\n4        8325  1.000000e+00  4.175861e-09\n\nPrediction distribution:\nSPAM/HAM\n1    561\n0    439\nName: count, dtype: int64\n\nProbability statistics:\nAverage prob_ham: 0.4338\nAverage prob_spam: 0.5662\n\nFirst few rows of submission:\n      ID  SPAM/HAM\n0  22428         1\n1   4971         1\n2  16377         0\n3   5097         1\n4   8325         0\n5   3573         0\n6  26514         1\n7  18155         1\n8  27106         1\n9   9809         1\n\nKaggle submission saved to: kaggle_submission.csv\n","output_type":"stream"}],"execution_count":9}]}